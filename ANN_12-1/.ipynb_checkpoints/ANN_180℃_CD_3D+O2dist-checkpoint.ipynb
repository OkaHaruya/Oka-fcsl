{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce7824c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore', FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eab3a947",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5753432b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61385086",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input = pd.read_csv('CD_3D+O2dist 0.4-0.9V_std', usecols=[1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bee2e1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output = pd. read_csv('CD_3D+O2dist 0.4-0.9V_std', usecols=[5,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6aa258fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85096, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c9360c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85096, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67c463de",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df_input, df_output, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b16ab26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76586, 4) (8510, 4)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape,x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2036ac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x座標</th>\n",
       "      <th>y座標</th>\n",
       "      <th>z座標</th>\n",
       "      <th>V[V]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76695</th>\n",
       "      <td>-0.597975</td>\n",
       "      <td>1.384978</td>\n",
       "      <td>2.025275</td>\n",
       "      <td>1.264911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58668</th>\n",
       "      <td>0.157043</td>\n",
       "      <td>1.384978</td>\n",
       "      <td>-0.175997</td>\n",
       "      <td>0.632456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13136</th>\n",
       "      <td>-0.122811</td>\n",
       "      <td>1.908395</td>\n",
       "      <td>2.218961</td>\n",
       "      <td>-1.264911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72420</th>\n",
       "      <td>-1.417443</td>\n",
       "      <td>-0.769531</td>\n",
       "      <td>-0.553156</td>\n",
       "      <td>1.264911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43713</th>\n",
       "      <td>1.065470</td>\n",
       "      <td>-1.282510</td>\n",
       "      <td>0.106872</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21243</th>\n",
       "      <td>-0.048337</td>\n",
       "      <td>-1.907057</td>\n",
       "      <td>0.106872</td>\n",
       "      <td>-0.948683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45891</th>\n",
       "      <td>0.514740</td>\n",
       "      <td>-0.051362</td>\n",
       "      <td>0.106872</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42613</th>\n",
       "      <td>-1.417443</td>\n",
       "      <td>1.333680</td>\n",
       "      <td>0.106872</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43567</th>\n",
       "      <td>0.888119</td>\n",
       "      <td>0.205128</td>\n",
       "      <td>0.106872</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68268</th>\n",
       "      <td>0.171999</td>\n",
       "      <td>0.666808</td>\n",
       "      <td>2.218961</td>\n",
       "      <td>0.948683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76586 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            x座標       y座標       z座標      V[V]\n",
       "76695 -0.597975  1.384978  2.025275  1.264911\n",
       "58668  0.157043  1.384978 -0.175997  0.632456\n",
       "13136 -0.122811  1.908395  2.218961 -1.264911\n",
       "72420 -1.417443 -0.769531 -0.553156  1.264911\n",
       "43713  1.065470 -1.282510  0.106872  0.000000\n",
       "...         ...       ...       ...       ...\n",
       "21243 -0.048337 -1.907057  0.106872 -0.948683\n",
       "45891  0.514740 -0.051362  0.106872  0.000000\n",
       "42613 -1.417443  1.333680  0.106872  0.000000\n",
       "43567  0.888119  0.205128  0.106872  0.000000\n",
       "68268  0.171999  0.666808  2.218961  0.948683\n",
       "\n",
       "[76586 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f2b908c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i[A/m^2]</th>\n",
       "      <th>c[mol/m^3]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76695</th>\n",
       "      <td>-0.478544</td>\n",
       "      <td>0.938510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58668</th>\n",
       "      <td>-0.478544</td>\n",
       "      <td>0.520132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13136</th>\n",
       "      <td>-0.478544</td>\n",
       "      <td>0.033019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72420</th>\n",
       "      <td>-0.203969</td>\n",
       "      <td>0.731965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43713</th>\n",
       "      <td>-0.478544</td>\n",
       "      <td>0.455846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21243</th>\n",
       "      <td>-0.478544</td>\n",
       "      <td>1.290436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45891</th>\n",
       "      <td>-0.478544</td>\n",
       "      <td>0.657754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42613</th>\n",
       "      <td>-0.478544</td>\n",
       "      <td>-0.286725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43567</th>\n",
       "      <td>-0.478544</td>\n",
       "      <td>0.172121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68268</th>\n",
       "      <td>-0.478544</td>\n",
       "      <td>0.952975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76586 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       i[A/m^2]  c[mol/m^3]\n",
       "76695 -0.478544    0.938510\n",
       "58668 -0.478544    0.520132\n",
       "13136 -0.478544    0.033019\n",
       "72420 -0.203969    0.731965\n",
       "43713 -0.478544    0.455846\n",
       "...         ...         ...\n",
       "21243 -0.478544    1.290436\n",
       "45891 -0.478544    0.657754\n",
       "42613 -0.478544   -0.286725\n",
       "43567 -0.478544    0.172121\n",
       "68268 -0.478544    0.952975\n",
       "\n",
       "[76586 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8453f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras import regularizers, initializers\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "weights = [com.get_weights() for com in model.layers[0:]]  #重さを抽出（※始めに回すときだけ下の行と入れ替える）\n",
    "\n",
    "\n",
    "\n",
    "model.add(Dense(units=32, input_shape=(4,), activation='tanh'))  \n",
    "model.add(Dense(units=10, activation='tanh'))  #xとyが-1～1なのでtanh\n",
    "model.add(Dense(units=10, activation='tanh'))\n",
    "model.add(Dense(units=2, activation='linear'))  #隠れ層3層でやってみる\n",
    "\n",
    "model.compile(loss='mean_squared_error',    #出力は連続値なので平均二乗誤差\n",
    "              optimizer='adam',             #とりあえずadamで\n",
    "              metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "232c27be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 76586 samples, validate on 8510 samples\n",
      "Epoch 1/20000\n",
      "76586/76586 [==============================] - 1s 16us/sample - loss: 0.3787 - mse: 0.3787 - val_loss: 0.1780 - val_mse: 0.1780\n",
      "Epoch 2/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.1340 - mse: 0.1340 - val_loss: 0.0967 - val_mse: 0.0967\n",
      "Epoch 3/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0812 - mse: 0.0812 - val_loss: 0.0696 - val_mse: 0.0696\n",
      "Epoch 4/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0643 - mse: 0.0643 - val_loss: 0.0596 - val_mse: 0.0596\n",
      "Epoch 5/20000\n",
      "76586/76586 [==============================] - ETA: 0s - loss: 0.0573 - mse: 0.057 - 1s 8us/sample - loss: 0.0571 - mse: 0.0571 - val_loss: 0.0563 - val_mse: 0.0563\n",
      "Epoch 6/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0527 - mse: 0.0527 - val_loss: 0.0492 - val_mse: 0.0492\n",
      "Epoch 7/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0489 - mse: 0.0489 - val_loss: 0.0453 - val_mse: 0.0453\n",
      "Epoch 8/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0462 - mse: 0.0462 - val_loss: 0.0425 - val_mse: 0.0425\n",
      "Epoch 9/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0442 - mse: 0.0442 - val_loss: 0.0412 - val_mse: 0.0412\n",
      "Epoch 10/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0419 - mse: 0.0419 - val_loss: 0.0394 - val_mse: 0.0394\n",
      "Epoch 11/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0404 - mse: 0.0404 - val_loss: 0.0391 - val_mse: 0.0391\n",
      "Epoch 12/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0392 - mse: 0.0392 - val_loss: 0.0377 - val_mse: 0.0377\n",
      "Epoch 13/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0377 - mse: 0.0377 - val_loss: 0.0352 - val_mse: 0.0352\n",
      "Epoch 14/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0367 - mse: 0.0367 - val_loss: 0.0345 - val_mse: 0.0345\n",
      "Epoch 15/20000\n",
      "76586/76586 [==============================] - 1s 13us/sample - loss: 0.0354 - mse: 0.0354 - val_loss: 0.0354 - val_mse: 0.0354\n",
      "Epoch 16/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0344 - mse: 0.0344 - val_loss: 0.0332 - val_mse: 0.0332\n",
      "Epoch 17/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0336 - mse: 0.0336 - val_loss: 0.0316 - val_mse: 0.0316 0s - loss: 0.0335 - mse: 0.\n",
      "Epoch 18/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0325 - mse: 0.0325 - val_loss: 0.0304 - val_mse: 0.0304\n",
      "Epoch 19/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0316 - mse: 0.0316 - val_loss: 0.0310 - val_mse: 0.0310\n",
      "Epoch 20/20000\n",
      "76586/76586 [==============================] - 1s 12us/sample - loss: 0.0312 - mse: 0.0312 - val_loss: 0.0303 - val_mse: 0.0303\n",
      "Epoch 21/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0302 - mse: 0.0302 - val_loss: 0.0278 - val_mse: 0.0278\n",
      "Epoch 22/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0296 - mse: 0.0296 - val_loss: 0.0289 - val_mse: 0.0289\n",
      "Epoch 23/20000\n",
      "76586/76586 [==============================] - ETA: 0s - loss: 0.0289 - mse: 0.028 - 1s 12us/sample - loss: 0.0288 - mse: 0.0288 - val_loss: 0.0269 - val_mse: 0.0269\n",
      "Epoch 24/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0285 - mse: 0.0285 - val_loss: 0.0273 - val_mse: 0.0273\n",
      "Epoch 25/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0275 - mse: 0.0275 - val_loss: 0.0268 - val_mse: 0.0268\n",
      "Epoch 26/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0270 - mse: 0.0270 - val_loss: 0.0250 - val_mse: 0.0250\n",
      "Epoch 27/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0267 - mse: 0.0267 - val_loss: 0.0267 - val_mse: 0.0267\n",
      "Epoch 28/20000\n",
      "76586/76586 [==============================] - 1s 12us/sample - loss: 0.0262 - mse: 0.0262 - val_loss: 0.0240 - val_mse: 0.0240\n",
      "Epoch 29/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0257 - mse: 0.0257 - val_loss: 0.0241 - val_mse: 0.0241\n",
      "Epoch 30/20000\n",
      "76586/76586 [==============================] - 1s 11us/sample - loss: 0.0251 - mse: 0.0251 - val_loss: 0.0232 - val_mse: 0.0232\n",
      "Epoch 31/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0247 - mse: 0.0247 - val_loss: 0.0254 - val_mse: 0.0254\n",
      "Epoch 32/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0245 - mse: 0.0245 - val_loss: 0.0234 - val_mse: 0.0234\n",
      "Epoch 33/20000\n",
      "76586/76586 [==============================] - 1s 11us/sample - loss: 0.0244 - mse: 0.0244 - val_loss: 0.0226 - val_mse: 0.0226\n",
      "Epoch 34/20000\n",
      "76586/76586 [==============================] - 1s 11us/sample - loss: 0.0240 - mse: 0.0240 - val_loss: 0.0238 - val_mse: 0.0238\n",
      "Epoch 35/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0237 - mse: 0.0237 - val_loss: 0.0216 - val_mse: 0.0216\n",
      "Epoch 36/20000\n",
      "76586/76586 [==============================] - 1s 11us/sample - loss: 0.0232 - mse: 0.0232 - val_loss: 0.0220 - val_mse: 0.0220\n",
      "Epoch 37/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0231 - mse: 0.0231 - val_loss: 0.0211 - val_mse: 0.0211\n",
      "Epoch 38/20000\n",
      "76586/76586 [==============================] - 1s 12us/sample - loss: 0.0227 - mse: 0.0227 - val_loss: 0.0224 - val_mse: 0.0224\n",
      "Epoch 39/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0226 - mse: 0.0226 - val_loss: 0.0212 - val_mse: 0.0212\n",
      "Epoch 40/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0223 - mse: 0.0223 - val_loss: 0.0252 - val_mse: 0.0252\n",
      "Epoch 41/20000\n",
      "76586/76586 [==============================] - 1s 11us/sample - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0202 - val_mse: 0.0202\n",
      "Epoch 42/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0207 - val_mse: 0.0207\n",
      "Epoch 43/20000\n",
      "76586/76586 [==============================] - 1s 12us/sample - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 44/20000\n",
      "76586/76586 [==============================] - 1s 11us/sample - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 45/20000\n",
      "76586/76586 [==============================] - 1s 12us/sample - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0213 - val_mse: 0.0213\n",
      "Epoch 46/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 47/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 48/20000\n",
      "76586/76586 [==============================] - 1s 15us/sample - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0208 - val_mse: 0.0208\n",
      "Epoch 49/20000\n",
      "76586/76586 [==============================] - ETA: 0s - loss: 0.0201 - mse: 0.020 - 1s 11us/sample - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 50/20000\n",
      "76586/76586 [==============================] - 1s 13us/sample - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 51/20000\n",
      "76586/76586 [==============================] - 1s 11us/sample - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0213 - val_mse: 0.0213\n",
      "Epoch 52/20000\n",
      "76586/76586 [==============================] - 1s 11us/sample - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0211 - val_mse: 0.0211\n",
      "Epoch 53/20000\n",
      "76586/76586 [==============================] - 1s 11us/sample - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0201 - val_mse: 0.0201\n",
      "Epoch 54/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 55/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 56/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 57/20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76586/76586 [==============================] - 1s 12us/sample - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 58/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 59/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 60/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 61/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0208 - val_mse: 0.0208\n",
      "Epoch 62/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0206 - val_mse: 0.0206\n",
      "Epoch 63/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0189 - val_mse: 0.0189\n",
      "Epoch 64/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 65/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 66/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 67/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 68/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 69/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 70/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 71/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 72/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 73/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 74/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 75/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 76/20000\n",
      "76586/76586 [==============================] - ETA: 0s - loss: 0.0154 - mse: 0.015 - 1s 8us/sample - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 77/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 78/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 79/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 80/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 81/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 82/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 83/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 84/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 85/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 86/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 87/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 88/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 89/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 90/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 91/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 92/20000\n",
      "76586/76586 [==============================] - 1s 15us/sample - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 93/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 94/20000\n",
      "76586/76586 [==============================] - ETA: 0s - loss: 0.0137 - mse: 0.013 - 1s 11us/sample - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 95/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 96/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 97/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 98/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 99/20000\n",
      "76586/76586 [==============================] - 1s 13us/sample - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 100/20000\n",
      "76586/76586 [==============================] - 1s 14us/sample - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 101/20000\n",
      "76586/76586 [==============================] - ETA: 0s - loss: 0.0132 - mse: 0.013 - 1s 9us/sample - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 102/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 103/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 104/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 105/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 106/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 107/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 108/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 109/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 110/20000\n",
      "76586/76586 [==============================] - 1s 14us/sample - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 111/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 112/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 113/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0136 - val_mse: 0.0136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 115/20000\n",
      "76586/76586 [==============================] - 1s 11us/sample - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0124 - val_mse: 0.0124\n",
      "Epoch 116/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 117/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0129 - val_mse: 0.0129 0.0131 - mse: 0.013\n",
      "Epoch 118/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 119/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 120/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 121/20000\n",
      "76586/76586 [==============================] - 1s 15us/sample - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 122/20000\n",
      "76586/76586 [==============================] - 1s 15us/sample - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0124 - val_mse: 0.0124\n",
      "Epoch 123/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0124 - val_mse: 0.0124\n",
      "Epoch 124/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 125/20000\n",
      "76586/76586 [==============================] - 1s 13us/sample - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 126/20000\n",
      "76586/76586 [==============================] - 1s 16us/sample - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 127/20000\n",
      "76586/76586 [==============================] - 1s 13us/sample - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 128/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0125 - val_mse: 0.0125\n",
      "Epoch 129/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 130/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 131/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 132/20000\n",
      "76586/76586 [==============================] - 1s 15us/sample - loss: 0.0119 - mse: 0.0119 - val_loss: 0.0119 - val_mse: 0.0119\n",
      "Epoch 133/20000\n",
      "76586/76586 [==============================] - 1s 12us/sample - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 134/20000\n",
      "76586/76586 [==============================] - 1s 14us/sample - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 135/20000\n",
      "76586/76586 [==============================] - 1s 12us/sample - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 136/20000\n",
      "76586/76586 [==============================] - 1s 11us/sample - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 137/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 138/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0120 - mse: 0.0120 - val_loss: 0.0126 - val_mse: 0.0126\n",
      "Epoch 139/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0121 - mse: 0.0121 - val_loss: 0.0125 - val_mse: 0.0125\n",
      "Epoch 140/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0120 - mse: 0.0120 - val_loss: 0.0123 - val_mse: 0.0123\n",
      "Epoch 141/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 142/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0112 - val_mse: 0.0112\n",
      "Epoch 143/20000\n",
      "76586/76586 [==============================] - 1s 11us/sample - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0121 - val_mse: 0.0121\n",
      "Epoch 144/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0121 - mse: 0.0121 - val_loss: 0.0118 - val_mse: 0.0118\n",
      "Epoch 145/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0120 - mse: 0.0120 - val_loss: 0.0122 - val_mse: 0.0122\n",
      "Epoch 146/20000\n",
      "76586/76586 [==============================] - 1s 12us/sample - loss: 0.0118 - mse: 0.0118 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 147/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0122 - val_mse: 0.0122\n",
      "Epoch 148/20000\n",
      "76586/76586 [==============================] - 1s 13us/sample - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 149/20000\n",
      "76586/76586 [==============================] - 1s 11us/sample - loss: 0.0118 - mse: 0.0118 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 150/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0118 - val_mse: 0.0118\n",
      "Epoch 151/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0116 - mse: 0.0116 - val_loss: 0.0119 - val_mse: 0.0119\n",
      "Epoch 152/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0119 - mse: 0.0119 - val_loss: 0.0120 - val_mse: 0.0120\n",
      "Epoch 153/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 154/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0114 - mse: 0.0114 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 155/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0118 - mse: 0.0118 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 156/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0120 - mse: 0.0120 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 157/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0120 - mse: 0.0120 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 158/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0118 - mse: 0.0118 - val_loss: 0.0117 - val_mse: 0.0117\n",
      "Epoch 159/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0117 - mse: 0.0117 - val_loss: 0.0114 - val_mse: 0.0114\n",
      "Epoch 160/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0113 - mse: 0.0113 - val_loss: 0.0112 - val_mse: 0.0112\n",
      "Epoch 161/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0116 - mse: 0.0116 - val_loss: 0.0126 - val_mse: 0.0126\n",
      "Epoch 162/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0119 - mse: 0.0119 - val_loss: 0.0121 - val_mse: 0.0121\n",
      "Epoch 163/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0114 - mse: 0.0114 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 164/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0117 - mse: 0.0117 - val_loss: 0.0125 - val_mse: 0.0125\n",
      "Epoch 165/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0116 - mse: 0.0116 - val_loss: 0.0113 - val_mse: 0.0113\n",
      "Epoch 166/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0114 - mse: 0.0114 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 167/20000\n",
      "76586/76586 [==============================] - ETA: 0s - loss: 0.0120 - mse: 0.012 - 1s 10us/sample - loss: 0.0120 - mse: 0.0120 - val_loss: 0.0113 - val_mse: 0.0113\n",
      "Epoch 168/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0119 - mse: 0.0119 - val_loss: 0.0110 - val_mse: 0.0110\n",
      "Epoch 169/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0114 - mse: 0.0114 - val_loss: 0.0120 - val_mse: 0.0120\n",
      "Epoch 170/20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0114 - mse: 0.0114 - val_loss: 0.0122 - val_mse: 0.0122\n",
      "Epoch 171/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0114 - mse: 0.0114 - val_loss: 0.0108 - val_mse: 0.0108\n",
      "Epoch 172/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0119 - mse: 0.0119 - val_loss: 0.0108 - val_mse: 0.0108\n",
      "Epoch 173/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0117 - mse: 0.0117 - val_loss: 0.0116 - val_mse: 0.0116\n",
      "Epoch 174/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0112 - mse: 0.0112 - val_loss: 0.0123 - val_mse: 0.0123\n",
      "Epoch 175/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0117 - mse: 0.0117 - val_loss: 0.0122 - val_mse: 0.0122\n",
      "Epoch 176/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0112 - mse: 0.0112 - val_loss: 0.0112 - val_mse: 0.0112\n",
      "Epoch 177/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0112 - mse: 0.0112 - val_loss: 0.0106 - val_mse: 0.0106\n",
      "Epoch 178/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0118 - mse: 0.0118 - val_loss: 0.0109 - val_mse: 0.0109\n",
      "Epoch 179/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0114 - mse: 0.0114 - val_loss: 0.0122 - val_mse: 0.0122\n",
      "Epoch 180/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0120 - mse: 0.0120 - val_loss: 0.0115 - val_mse: 0.0115\n",
      "Epoch 181/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0112 - mse: 0.0112 - val_loss: 0.0124 - val_mse: 0.0124\n",
      "Epoch 182/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0116 - mse: 0.0116 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 183/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0116 - mse: 0.0116 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 184/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0111 - mse: 0.0111 - val_loss: 0.0117 - val_mse: 0.0117\n",
      "Epoch 185/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0117 - mse: 0.0117 - val_loss: 0.0104 - val_mse: 0.0104\n",
      "Epoch 186/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0114 - mse: 0.0114 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 187/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0114 - mse: 0.0114 - val_loss: 0.0126 - val_mse: 0.0126\n",
      "Epoch 188/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0118 - mse: 0.0118 - val_loss: 0.0119 - val_mse: 0.0119\n",
      "Epoch 189/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0115 - mse: 0.0115 - val_loss: 0.0105 - val_mse: 0.0105\n",
      "Epoch 190/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0113 - mse: 0.0113 - val_loss: 0.0106 - val_mse: 0.0106\n",
      "Epoch 191/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0113 - mse: 0.0113 - val_loss: 0.0125 - val_mse: 0.0125\n",
      "Epoch 192/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0112 - mse: 0.0112 - val_loss: 0.0122 - val_mse: 0.0122\n",
      "Epoch 193/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0114 - mse: 0.0114 - val_loss: 0.0105 - val_mse: 0.0105\n",
      "Epoch 194/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0112 - mse: 0.0112 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 195/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0112 - mse: 0.0112 - val_loss: 0.0105 - val_mse: 0.0105\n",
      "Epoch 196/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0110 - mse: 0.0110 - val_loss: 0.0114 - val_mse: 0.0114\n",
      "Epoch 197/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0116 - mse: 0.0116 - val_loss: 0.0111 - val_mse: 0.0111\n",
      "Epoch 198/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0113 - mse: 0.0113 - val_loss: 0.0109 - val_mse: 0.0109\n",
      "Epoch 199/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0112 - val_mse: 0.0112\n",
      "Epoch 200/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0110 - mse: 0.0110 - val_loss: 0.0108 - val_mse: 0.0108\n",
      "Epoch 201/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0112 - mse: 0.0112 - val_loss: 0.0125 - val_mse: 0.0125\n",
      "Epoch 202/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0115 - mse: 0.0115 - val_loss: 0.0110 - val_mse: 0.0110\n",
      "Epoch 203/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0109 - mse: 0.0109 - val_loss: 0.0101 - val_mse: 0.0101\n",
      "Epoch 204/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 205/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0110 - mse: 0.0110 - val_loss: 0.0102 - val_mse: 0.0102\n",
      "Epoch 206/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0109 - mse: 0.0109 - val_loss: 0.0118 - val_mse: 0.0118\n",
      "Epoch 207/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0108 - mse: 0.0108 - val_loss: 0.0100 - val_mse: 0.0100\n",
      "Epoch 208/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0110 - mse: 0.0110 - val_loss: 0.0124 - val_mse: 0.0124\n",
      "Epoch 209/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0110 - mse: 0.0110 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 210/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0112 - val_mse: 0.0112\n",
      "Epoch 211/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0109 - mse: 0.0109 - val_loss: 0.0112 - val_mse: 0.0112\n",
      "Epoch 212/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0112 - val_mse: 0.0112\n",
      "Epoch 213/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0108 - mse: 0.0108 - val_loss: 0.0112 - val_mse: 0.0112\n",
      "Epoch 214/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0110 - mse: 0.0110 - val_loss: 0.0108 - val_mse: 0.0108\n",
      "Epoch 215/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0113 - val_mse: 0.0113\n",
      "Epoch 216/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0109 - mse: 0.0109 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 217/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0108 - mse: 0.0108 - val_loss: 0.0120 - val_mse: 0.0120\n",
      "Epoch 218/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0109 - mse: 0.0109 - val_loss: 0.0112 - val_mse: 0.0112\n",
      "Epoch 219/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0119 - val_mse: 0.0119\n",
      "Epoch 220/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0112 - mse: 0.0112 - val_loss: 0.0110 - val_mse: 0.0110\n",
      "Epoch 221/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0126 - val_mse: 0.0126\n",
      "Epoch 222/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0113 - mse: 0.0113 - val_loss: 0.0106 - val_mse: 0.0106\n",
      "Epoch 223/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0104 - val_mse: 0.0104\n",
      "Epoch 224/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0108 - mse: 0.0108 - val_loss: 0.0117 - val_mse: 0.0117\n",
      "Epoch 225/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0107 - val_mse: 0.0107\n",
      "Epoch 226/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 227/20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0110 - mse: 0.0110 - val_loss: 0.0119 - val_mse: 0.0119 loss: 0.0111 - mse: 0.0\n",
      "Epoch 228/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0108 - mse: 0.0108 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 229/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0106 - mse: 0.0106 - val_loss: 0.0117 - val_mse: 0.0117\n",
      "Epoch 230/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0106 - mse: 0.0106 - val_loss: 0.0100 - val_mse: 0.0100\n",
      "Epoch 231/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0108 - mse: 0.0108 - val_loss: 0.0119 - val_mse: 0.0119\n",
      "Epoch 232/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0108 - mse: 0.0108 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 233/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0109 - mse: 0.0109 - val_loss: 0.0110 - val_mse: 0.0110\n",
      "Epoch 234/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0110 - mse: 0.0110 - val_loss: 0.0108 - val_mse: 0.0108\n",
      "Epoch 235/20000\n",
      "76586/76586 [==============================] - 1s 11us/sample - loss: 0.0108 - mse: 0.0108 - val_loss: 0.0109 - val_mse: 0.0109\n",
      "Epoch 236/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0111 - val_mse: 0.0111\n",
      "Epoch 237/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0111 - val_mse: 0.0111\n",
      "Epoch 238/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0120 - val_mse: 0.0120\n",
      "Epoch 239/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0106 - mse: 0.0106 - val_loss: 0.0116 - val_mse: 0.0116\n",
      "Epoch 240/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0103 - val_mse: 0.0103\n",
      "Epoch 241/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0116 - val_mse: 0.0116\n",
      "Epoch 242/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0112 - val_mse: 0.0112\n",
      "Epoch 243/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0113 - val_mse: 0.0113\n",
      "Epoch 244/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0113 - val_mse: 0.0113\n",
      "Epoch 245/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0113 - val_mse: 0.0113\n",
      "Epoch 246/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0107 - val_mse: 0.0107\n",
      "Epoch 247/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0115 - val_mse: 0.0115\n",
      "Epoch 248/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0103 - val_mse: 0.0103\n",
      "Epoch 249/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0103 - val_mse: 0.0103\n",
      "Epoch 250/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 251/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0104 - val_mse: 0.0104\n",
      "Epoch 252/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0108 - val_mse: 0.0108\n",
      "Epoch 253/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0111 - val_mse: 0.0111\n",
      "Epoch 254/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0106 - mse: 0.0106 - val_loss: 0.0104 - val_mse: 0.0104\n",
      "Epoch 255/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0098 - val_mse: 0.0098\n",
      "Epoch 256/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0106 - mse: 0.0106 - val_loss: 0.0113 - val_mse: 0.0113\n",
      "Epoch 257/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0096 - val_mse: 0.0096\n",
      "Epoch 258/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0126 - val_mse: 0.0126\n",
      "Epoch 259/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0101 - val_mse: 0.0101\n",
      "Epoch 260/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0107 - val_mse: 0.0107\n",
      "Epoch 261/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0113 - val_mse: 0.0113\n",
      "Epoch 262/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 263/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0096 - val_mse: 0.0096\n",
      "Epoch 264/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 265/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0099 - val_mse: 0.0099\n",
      "Epoch 266/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0100 - val_mse: 0.0100\n",
      "Epoch 267/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0114 - val_mse: 0.0114\n",
      "Epoch 268/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0112 - val_mse: 0.0112\n",
      "Epoch 269/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0113 - val_mse: 0.0113\n",
      "Epoch 270/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0100 - val_mse: 0.0100\n",
      "Epoch 271/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0100 - val_mse: 0.0100\n",
      "Epoch 272/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 273/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0106 - val_mse: 0.0106\n",
      "Epoch 274/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0096 - val_mse: 0.0096\n",
      "Epoch 275/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0126 - val_mse: 0.0126\n",
      "Epoch 276/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0096 - val_mse: 0.0096\n",
      "Epoch 277/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0103 - val_mse: 0.0103\n",
      "Epoch 278/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0093 - val_mse: 0.0093\n",
      "Epoch 279/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0093 - val_mse: 0.0093\n",
      "Epoch 280/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0122 - val_mse: 0.0122\n",
      "Epoch 281/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0102 - val_mse: 0.0102\n",
      "Epoch 282/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 283/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0099 - val_mse: 0.0099\n",
      "Epoch 284/20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0121 - val_mse: 0.0121\n",
      "Epoch 285/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0107 - val_mse: 0.0107\n",
      "Epoch 286/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0113 - val_mse: 0.0113\n",
      "Epoch 287/20000\n",
      "76586/76586 [==============================] - 1s 12us/sample - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0125 - val_mse: 0.0125\n",
      "Epoch 288/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 289/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0106 - val_mse: 0.0106\n",
      "Epoch 290/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0098 - val_mse: 0.0098\n",
      "Epoch 291/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0108 - val_mse: 0.0108\n",
      "Epoch 292/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0100 - val_mse: 0.0100\n",
      "Epoch 293/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0109 - val_mse: 0.0109\n",
      "Epoch 294/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0103 - val_mse: 0.0103\n",
      "Epoch 295/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0102 - val_mse: 0.0102\n",
      "Epoch 296/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0112 - val_mse: 0.0112\n",
      "Epoch 297/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0107 - val_mse: 0.0107\n",
      "Epoch 298/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0098 - val_mse: 0.0098\n",
      "Epoch 299/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0104 - val_mse: 0.0104\n",
      "Epoch 300/20000\n",
      "76586/76586 [==============================] - 1s 11us/sample - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 301/20000\n",
      "76586/76586 [==============================] - 1s 15us/sample - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0096 - val_mse: 0.0096\n",
      "Epoch 302/20000\n",
      "76586/76586 [==============================] - 1s 17us/sample - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 303/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0100 - val_mse: 0.0100\n",
      "Epoch 304/20000\n",
      "76586/76586 [==============================] - 1s 14us/sample - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0115 - val_mse: 0.0115\n",
      "Epoch 305/20000\n",
      "76586/76586 [==============================] - 1s 11us/sample - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0109 - val_mse: 0.0109\n",
      "Epoch 306/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 307/20000\n",
      "76586/76586 [==============================] - ETA: 0s - loss: 0.0102 - mse: 0.0102- ETA: 0s - loss: 0.0102 - 1s 11us/sample - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0093 - val_mse: 0.0093\n",
      "Epoch 308/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0091 - val_mse: 0.0091\n",
      "Epoch 309/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0101 - val_mse: 0.0101\n",
      "Epoch 310/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0094 - val_mse: 0.0094\n",
      "Epoch 311/20000\n",
      "76586/76586 [==============================] - 1s 11us/sample - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0094 - val_mse: 0.0094\n",
      "Epoch 312/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0103 - val_mse: 0.0103\n",
      "Epoch 313/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0107 - val_mse: 0.0107\n",
      "Epoch 314/20000\n",
      "76586/76586 [==============================] - 1s 11us/sample - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 315/20000\n",
      "76586/76586 [==============================] - 1s 11us/sample - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0105 - val_mse: 0.0105\n",
      "Epoch 316/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0090 - val_mse: 0.0090\n",
      "Epoch 317/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0090 - val_mse: 0.0090\n",
      "Epoch 318/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0102 - val_mse: 0.0102\n",
      "Epoch 319/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0114 - val_mse: 0.0114\n",
      "Epoch 320/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0107 - val_mse: 0.0107\n",
      "Epoch 321/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0093 - val_mse: 0.0093\n",
      "Epoch 322/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0091 - val_mse: 0.0091\n",
      "Epoch 323/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0105 - val_mse: 0.0105\n",
      "Epoch 324/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0094 - val_mse: 0.0094\n",
      "Epoch 325/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0094 - val_mse: 0.0094\n",
      "Epoch 326/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 327/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 328/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0099 - val_mse: 0.0099\n",
      "Epoch 329/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 330/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 331/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0117 - val_mse: 0.0117\n",
      "Epoch 332/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0102 - val_mse: 0.0102\n",
      "Epoch 333/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 334/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "Epoch 335/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0090 - val_mse: 0.0090\n",
      "Epoch 336/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 337/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0093 - val_mse: 0.0093\n",
      "Epoch 338/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 339/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0091 - val_mse: 0.0091\n",
      "Epoch 340/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0083 - val_mse: 0.0083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 341/20000\n",
      "76586/76586 [==============================] - 1s 11us/sample - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0090 - val_mse: 0.0090\n",
      "Epoch 342/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0094 - val_mse: 0.0094\n",
      "Epoch 343/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 344/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0092 - val_mse: 0.0092\n",
      "Epoch 345/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 346/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 347/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0100 - val_mse: 0.0100\n",
      "Epoch 348/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 349/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0099 - val_mse: 0.0099\n",
      "Epoch 350/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 351/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0099 - val_mse: 0.0099\n",
      "Epoch 352/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0101 - val_mse: 0.0101\n",
      "Epoch 353/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0093 - val_mse: 0.0093s: 0.0093 - mse: 0.00\n",
      "Epoch 354/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 355/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0092 - val_mse: 0.0092\n",
      "Epoch 356/20000\n",
      "76586/76586 [==============================] - 1s 15us/sample - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0098 - val_mse: 0.0098\n",
      "Epoch 357/20000\n",
      "76586/76586 [==============================] - 1s 16us/sample - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0092 - val_mse: 0.0092\n",
      "Epoch 358/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 359/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0090 - val_mse: 0.0090 - loss: 0.0081 - ms\n",
      "Epoch 360/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 361/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0090 - val_mse: 0.0090\n",
      "Epoch 362/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0099 - val_mse: 0.0099\n",
      "Epoch 363/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0079 - val_mse: 0.0079\n",
      "Epoch 364/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0093 - val_mse: 0.0093\n",
      "Epoch 365/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 366/20000\n",
      "76586/76586 [==============================] - ETA: 0s - loss: 0.0094 - mse: 0.0094- ETA: 0s - loss: 0.0090 - mse: 0 - 1s 10us/sample - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0104 - val_mse: 0.0104\n",
      "Epoch 367/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0092 - val_mse: 0.0092\n",
      "Epoch 368/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0090 - val_mse: 0.0090\n",
      "Epoch 369/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0078 - val_mse: 0.0078\n",
      "Epoch 370/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0087 - mse: 0.0087 - val_loss: 0.0080 - val_mse: 0.0080\n",
      "Epoch 371/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 372/20000\n",
      "76586/76586 [==============================] - 1s 11us/sample - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 373/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0090 - val_mse: 0.0090\n",
      "Epoch 374/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0110 - val_mse: 0.0110\n",
      "Epoch 375/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "Epoch 376/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 377/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0104 - val_mse: 0.0104\n",
      "Epoch 378/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0102 - val_mse: 0.0102\n",
      "Epoch 379/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0104 - val_mse: 0.0104\n",
      "Epoch 380/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0094 - val_mse: 0.0094\n",
      "Epoch 381/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 382/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 383/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0087 - mse: 0.0087 - val_loss: 0.0092 - val_mse: 0.0092\n",
      "Epoch 384/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0079 - val_mse: 0.0079\n",
      "Epoch 385/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "Epoch 386/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "Epoch 387/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0081 - val_mse: 0.0081\n",
      "Epoch 388/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0086 - mse: 0.0086 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 389/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0085 - mse: 0.0085 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 390/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0102 - val_mse: 0.0102\n",
      "Epoch 391/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0081 - val_mse: 0.0081\n",
      "Epoch 392/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 393/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0093 - val_mse: 0.0093\n",
      "Epoch 394/20000\n",
      "76586/76586 [==============================] - 1s 12us/sample - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 395/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 396/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0082 - val_mse: 0.0082\n",
      "Epoch 397/20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76586/76586 [==============================] - 1s 12us/sample - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0078 - val_mse: 0.0078\n",
      "Epoch 398/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 399/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0086 - mse: 0.0086 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 400/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0085 - mse: 0.0085 - val_loss: 0.0090 - val_mse: 0.0090\n",
      "Epoch 401/20000\n",
      "76586/76586 [==============================] - 1s 8us/sample - loss: 0.0085 - mse: 0.0085 - val_loss: 0.0082 - val_mse: 0.0082\n",
      "Epoch 402/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0086 - mse: 0.0086 - val_loss: 0.0094 - val_mse: 0.0094\n",
      "Epoch 403/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0087 - mse: 0.0087 - val_loss: 0.0091 - val_mse: 0.0091\n",
      "Epoch 404/20000\n",
      "76586/76586 [==============================] - 1s 11us/sample - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0079 - val_mse: 0.0079\n",
      "Epoch 405/20000\n",
      "76586/76586 [==============================] - 1s 11us/sample - loss: 0.0086 - mse: 0.0086 - val_loss: 0.0100 - val_mse: 0.0100\n",
      "Epoch 406/20000\n",
      "76586/76586 [==============================] - 1s 11us/sample - loss: 0.0087 - mse: 0.0087 - val_loss: 0.0090 - val_mse: 0.0090\n",
      "Epoch 407/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0079 - val_mse: 0.0079\n",
      "Epoch 408/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0113 - val_mse: 0.0113\n",
      "Epoch 409/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0083 - mse: 0.0083 - val_loss: 0.0079 - val_mse: 0.0079\n",
      "Epoch 410/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "Epoch 411/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0085 - mse: 0.0085 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 412/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 413/20000\n",
      "76586/76586 [==============================] - 1s 10us/sample - loss: 0.0085 - mse: 0.0085 - val_loss: 0.0112 - val_mse: 0.0112\n",
      "Epoch 414/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0086 - mse: 0.0086 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 415/20000\n",
      "76586/76586 [==============================] - ETA: 0s - loss: 0.0091 - mse: 0.009 - ETA: 0s - loss: 0.0090 - mse: 0.009 - 1s 9us/sample - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0103 - val_mse: 0.0103\n",
      "Epoch 416/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0086 - mse: 0.0086 - val_loss: 0.0099 - val_mse: 0.0099\n",
      "Epoch 417/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0087 - mse: 0.0087 - val_loss: 0.0093 - val_mse: 0.0093\n",
      "Epoch 418/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0082 - mse: 0.0082 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 419/20000\n",
      "76586/76586 [==============================] - 1s 9us/sample - loss: 0.0083 - mse: 0.0083 - val_loss: 0.0084 - val_mse: 0.0084\n"
     ]
    }
   ],
   "source": [
    "callbacks1 = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_mse',\n",
    "                            factor=0.2,\n",
    "                            patience=5,\n",
    "                            mode=\"auto\",\n",
    "                            min_lr=0.001)\n",
    "callbacks2 = tf.keras.callbacks.EarlyStopping(monitor=\"val_mse\",\n",
    "                                              patience=50,\n",
    "                                              mode=\"auto\")\n",
    "history =  model.fit(x=x_train,\n",
    "                     y=y_train,\n",
    "                     epochs = 20000,\n",
    "                     batch_size=200,\n",
    "                     validation_data=(x_test, y_test),\n",
    "                     callbacks=[callbacks1,callbacks2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd9f2af9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'mse', 'val_loss', 'val_mse', 'lr'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc9f31d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mse = history_dict['mse']\n",
    "val_mse = history_dict['val_mse']\n",
    "epochs = range(1, len(mse) + 1)\n",
    "\n",
    "plt.rcParams[\"font.size\"] = 15\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(epochs, mse, label='mse')\n",
    "plt.plot(epochs, val_mse, label='val_mse')\n",
    "plt.xlabel(\"epochs\",fontsize=20)\n",
    "plt.ylabel(\"error\",fontsize=20)\n",
    "plt.ylim((0,0.1))\n",
    "plt.legend(loc = 'best',fontsize=20)\n",
    "plt.savefig('mse_transition.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c937eb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [com.get_weights() for com in model.layers[0:]] \n",
    "model.layers[0].set_weights(weights[0])\n",
    "model.layers[1].set_weights(weights[1])\n",
    "model.layers[2].set_weights(weights[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce774755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\aruhy\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: i_predict CD_3D+O2dist\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('i_predict CD_3D+O2dist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d875e51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
